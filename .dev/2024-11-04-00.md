# 2024-11-04, Monday, 10:00 AM

In my last session, the next steps were:

1. Make sure redeploys happen automatically on `git push`.
2. Make sure the build system is picking up the config in `apprunner.yaml`
3. Upgrade the `hello, world` to the Twilio Voice version of `hello, world`.

I implemented (3) and took it a few steps further. At the moment, when you call my Twilio number, here's what happens:

1. Twilio calls our webhook endpoint
2. Our webhook responds with instructions to create a websocket at a certain URL.
3. Twilio calls our websocket endpoint and streams the caller's audio over the websocket.

The very next steps are something like:

1. Figure out a way to test the audio stream (e.g. write it to a playable file)
2. Stream the audio to an S3 bucket
3. Figure out what the MVP looks like. For example, what are the minimal queues to the user (the caller). Do we need to say "stream started, stream stopped", etc. Does the MVP need to include provisions for sketchy connections? Etc.

I think in between 2 and 3 I'm actually going to go back to (1, 2) from my previous session. Generally speaking, my immediate goal is to have something that basically just works for user #1 (ME!).